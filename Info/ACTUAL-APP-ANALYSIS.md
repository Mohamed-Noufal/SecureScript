# âœ… Actual App Analysis - SecureScript

## What Your App ACTUALLY Uses

After carefully reading your code, here's what's **really** being used:

### Core Files (Actually Used):
1. **`server.py`** âœ… - Main FastAPI application
2. **`context.py`** âœ… - Security prompts for LLM

### Files NOT Used in Production:
3. **`mcp_servers.py`** âŒ - Defines MCP server config but **never imported** in server.py

---

## Dependencies Analysis

### Actually Used in `server.py`:
```python
âœ… fastapi          # Web framework
âœ… uvicorn          # ASGI server  
âœ… python-dotenv    # Environment variables
âœ… slowapi          # Rate limiting
âœ… pyjwt            # JWT verification
âœ… cryptography     # For JWT
âœ… httpx            # HTTP client (for Clerk JWKS)
âœ… openai           # AsyncOpenAI client (for Groq)
âœ… mangum           # Lambda adapter (serverless only)
```

### In pyproject.toml but NOT Used:
```python
âŒ mcp              # Model Context Protocol - NOT imported anywhere
âŒ openai-agents    # OpenAI Agents SDK - NOT imported anywhere  
âŒ groq             # Groq SDK - NOT used (you use openai client instead)
âŒ jwcrypto         # NOT used (you use pyjwt + cryptography)
```

---

## How Your App Works

### 1. Code Analysis Flow:
```
User â†’ FastAPI â†’ run_security_analysis_with_mcp() â†’ Groq API â†’ Response
```

**Note:** Despite the function name `run_security_analysis_with_mcp()`, it does **NOT** use MCP. It just calls Groq's API directly using the OpenAI client.

### 2. What Actually Happens:
```python
# Line 243-264 in server.py
client = AsyncOpenAI(
    api_key=os.getenv("GROQ_API_KEY"),
    base_url="https://api.groq.com/openai/v1"  # Direct Groq API call
)

response = await client.chat.completions.create(
    model="llama-3.3-70b-versatile",
    messages=[...],
    response_format={"type": "json_object"}
)
```

**No MCP, no agents, no Semgrep** - just a direct LLM API call!

---

## Corrected Dockerfile

### What Changed:
```dockerfile
# OLD (Incorrect):
COPY backend/ ./  # Copies everything including unused files

# NEW (Correct):
COPY backend/server.py ./
COPY backend/context.py ./
# mcp_servers.py is NOT copied (not used)
```

---

## Dependency Cleanup Recommendations

You can safely remove these from `pyproject.toml`:

```toml
# Remove (not used):
"mcp==1.12.2",              # Not imported
"openai-agents>=0.2.4",     # Not imported  
"groq>=0.4.0",              # Not used (using openai client)
"jwcrypto>=1.5.0",          # Not used (using pyjwt)
```

### Minimal Dependencies (What you actually need):
```toml
dependencies = [
    "fastapi>=0.116.1",
    "python-dotenv>=1.1.1",
    "uvicorn>=0.35.0",
    "httpx>=0.27.0",
    "openai>=1.0.0",          # For AsyncOpenAI
    "slowapi>=0.1.9",
    "pyjwt>=2.10.1",
    "cryptography>=46.0.3",
    "mangum>=0.17.0",         # Only for serverless
]
```

---

## Summary

**Your app is simpler than the dependencies suggest!**

âœ… **What it does:**
- Accepts code via FastAPI
- Sends it to Groq's Llama 3.3 70B
- Returns security analysis as JSON

âŒ **What it doesn't do:**
- Use MCP (Model Context Protocol)
- Use OpenAI Agents SDK
- Use Semgrep
- Use any agentic workflows

**The Dockerfile is now correct** - it only copies the 2 files you actually use! ğŸ¯
